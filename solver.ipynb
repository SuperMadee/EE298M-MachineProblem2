{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5ed7c39",
   "metadata": {},
   "source": [
    "### Machine Problem 2 - Polynomial Solver using SGD and Tinygrad Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "906bedff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to read the data train and data test csv files, the pandas library should be imported.\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c044ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the data train csv file in the df2 variable\n",
    "df2 = pd.read_csv('data_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2d0e03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ops_gpu not available No module named 'pyopencl'\n",
      "ops_opencl not available No module named 'pyopencl'\n",
      "ops_torch not available No module named 'torch'\n"
     ]
    }
   ],
   "source": [
    "# Import the Tensor module from tinygrad\n",
    "from tinygrad.tensor import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75ecb7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to read the contents of every tensor, import the numpy library\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7eb56a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-allocation of the x and y values of the data train csv file\n",
    "data_train_x = np.array(df2.x)\n",
    "data_train_y = np.array(df2.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c6c71c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the x and y values into Tensors\n",
    "data_train_x_tensor = Tensor([data_train_x])\n",
    "data_train_y_tensor = Tensor([data_train_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "422f69dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the class Polysolver that contains the self and the forward\n",
    "class PolySolver:\n",
    "  def __init__(self,n):\n",
    "    self.l1 = Tensor.uniform(1,n+1) # Initial guess for coefficients\n",
    "    self.n = n #Degree\n",
    "\n",
    "# Forward pass function. Will be used to calculate the output of the model using the input and the guess coefficients\n",
    "  def forward(self, x):\n",
    "    x_train = x**self.n\n",
    "    \n",
    "    for i in range(self.n-1,-1,-1):\n",
    "      x_train = Tensor.cat(x_train,x**i)\n",
    "\n",
    "    y_pred = self.l1@x_train\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f570108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree: 1, Epoch: 0, loss: [0.6742543]\n",
      "Degree: 1, Epoch: 500, loss: [0.07193436]\n",
      "Degree: 1, Epoch: 1000, loss: [0.03575504]\n",
      "Degree: 1, Epoch: 1500, loss: [0.02617304]\n",
      "Degree: 1, Epoch: 2000, loss: [0.02363526]\n",
      "Degree: 1, Epoch: 2500, loss: [0.02296315]\n",
      "Degree: 1, Epoch: 3000, loss: [0.02278513]\n",
      "Degree: 1, Epoch: 3500, loss: [0.02273799]\n",
      "Degree: 1, Epoch: 4000, loss: [0.0227255]\n",
      "Degree: 1, Epoch: 4500, loss: [0.0227222]\n",
      "Degree: 1, Epoch: 5000, loss: [0.02272132]\n",
      "Degree: 2, Epoch: 0, loss: [0.62126493]\n",
      "Degree: 2, Epoch: 500, loss: [0.02259254]\n",
      "Degree: 2, Epoch: 1000, loss: [0.02169535]\n",
      "Degree: 2, Epoch: 1500, loss: [0.02088627]\n",
      "Degree: 2, Epoch: 2000, loss: [0.02012375]\n",
      "Degree: 2, Epoch: 2500, loss: [0.01940218]\n",
      "Degree: 2, Epoch: 3000, loss: [0.01871913]\n",
      "Degree: 2, Epoch: 3500, loss: [0.01807251]\n",
      "Degree: 2, Epoch: 4000, loss: [0.01746039]\n",
      "Degree: 2, Epoch: 4500, loss: [0.01688091]\n",
      "Degree: 2, Epoch: 5000, loss: [0.01633235]\n",
      "Degree: 3, Epoch: 0, loss: [0.22076282]\n",
      "Degree: 3, Epoch: 500, loss: [0.01942291]\n",
      "Degree: 3, Epoch: 1000, loss: [0.01245417]\n",
      "Degree: 3, Epoch: 1500, loss: [0.01185481]\n",
      "Degree: 3, Epoch: 2000, loss: [0.01150924]\n",
      "Degree: 3, Epoch: 2500, loss: [0.01121184]\n",
      "Degree: 3, Epoch: 3000, loss: [0.01095077]\n",
      "Degree: 3, Epoch: 3500, loss: [0.01072121]\n",
      "Degree: 3, Epoch: 4000, loss: [0.01051911]\n",
      "Degree: 3, Epoch: 4500, loss: [0.01034095]\n",
      "Degree: 3, Epoch: 5000, loss: [0.01018366]\n",
      "Degree: 4, Epoch: 0, loss: [0.8247887]\n",
      "Degree: 4, Epoch: 500, loss: [0.0244678]\n",
      "Degree: 4, Epoch: 1000, loss: [0.02021877]\n",
      "Degree: 4, Epoch: 1500, loss: [0.01842998]\n",
      "Degree: 4, Epoch: 2000, loss: [0.01702314]\n",
      "Degree: 4, Epoch: 2500, loss: [0.0158962]\n",
      "Degree: 4, Epoch: 3000, loss: [0.01499087]\n",
      "Degree: 4, Epoch: 3500, loss: [0.0142613]\n",
      "Degree: 4, Epoch: 4000, loss: [0.01367112]\n",
      "Degree: 4, Epoch: 4500, loss: [0.01319152]\n",
      "Degree: 4, Epoch: 5000, loss: [0.01279964]\n"
     ]
    }
   ],
   "source": [
    "# Setting the epochs, learning rate and the pre-allocation of coefficients, degree and losses\n",
    "epochs = 5000\n",
    "lr = 0.01\n",
    "coeff = []\n",
    "degree = []\n",
    "loss_list = []\n",
    "\n",
    "# Instantiation of the model and the optimizer per degree from 1 to 4 (Abel-Ruffini Theorem and Doc Atienza's hint)\n",
    "for i in range(1,5):\n",
    "  import tinygrad.nn.optim as optim\n",
    "  model = PolySolver(i)\n",
    "  optim = optim.SGD([model.l1], lr=lr)\n",
    "\n",
    "# Storing the x and y training Tensors into X and Y variables for brevity purposes\n",
    "  X = data_train_x_tensor\n",
    "  Y = data_train_y_tensor\n",
    "\n",
    "# Min-Max Scaler to scale down the value\n",
    "  X= ((X-X.min())/(X.max()-X.min()))\n",
    "  Y= ((Y-Y.min())/(Y.max()-Y.min()))\n",
    "  \n",
    "  losslist = [] #to store losses\n",
    "\n",
    "# Training the Model\n",
    "  for ep in range(epochs+1):\n",
    "    preds = model.forward(X) #forward pass\n",
    "    loss = ((preds-Y)**2).mean() #loss function - MSE\n",
    "    optim.zero_grad() #zeroing gradients\n",
    "    loss.backward() #backward pass\n",
    "    optim.step() #parameter updates\n",
    "\n",
    "# Print the degree, epochs and losses every after 500 iterations\n",
    "    if ep%500 == 0:\n",
    "      print(\"Degree: {}, Epoch: {}, loss: {}\".format(i, ep, loss.data))\n",
    "      losslist.append(loss.data)\n",
    "  \n",
    "  coeff.append(model.l1.numpy())\n",
    "  degree.append(model.l1.shape[1]-1)\n",
    "  loss_list.append(loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40bf7109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The degree is 3 and the coefficients are [[ 0.5614795  0.2737577 -1.3189687  0.5701289]] with a loss of 0.010183660313487053\n"
     ]
    }
   ],
   "source": [
    "# Locates the values of the coefficients and degree with the least loss and prints it\n",
    "locator = loss_list.index(min(loss_list))\n",
    "print(\"The degree is {} and the coefficients are {} with a loss of {}\".format(degree[locator], coeff[locator], float(loss_list[locator])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5d8efdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model\n",
    "# Store the data test csv file in the df3 variable\n",
    "df3 = pd.read_csv('data_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a842cd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-allocation of the x and y values of the data train csv file\n",
    "data_test_x = np.array(df3.x)\n",
    "data_test_y = np.array(df3.y)\n",
    "\n",
    "# Transforming the values into Tensors\n",
    "data_test_x_tensor = Tensor([data_test_x])\n",
    "data_test_y_tensor = Tensor([data_test_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae7ee481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Degree of the locator\n",
    "m = int(degree[locator])\n",
    "\n",
    "# Storing the x and y test Tensors into Xt and Yt variables for brevity purposes\n",
    "Xt = data_test_x_tensor\n",
    "Yt = data_test_y_tensor\n",
    "\n",
    "# Min-Max Scaler\n",
    "Xt= ((Xt-Xt.min())/(Xt.max()-Xt.min()))\n",
    "Yt= ((Yt-Yt.min())/(Yt.max()-Yt.min()))\n",
    "\n",
    "# Calculating the error between the actual and predicted value for y \n",
    "x_test = Xt**m\n",
    "coefft = Tensor(coeff[locator])\n",
    "  \n",
    "for i in range(m-1,-1,-1):\n",
    "   x_test = Tensor.cat(x_test,Xt**i)\n",
    "\n",
    "y_test = coefft@x_test\n",
    "loss_test = ((y_test-Yt)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8437659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lost for the test data is 0.03853432461619377\n"
     ]
    }
   ],
   "source": [
    "# Prints the loss incurred when using the test data\n",
    "print(\"The lost for the test data is {}\" .format(float(loss_test.numpy())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
